{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2603b269-3bad-4d40-a185-6446d66d41ac",
   "metadata": {},
   "source": [
    "# Transform Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7662a7ac-cbbf-403e-8e7b-386845a75872",
   "metadata": {},
   "source": [
    "This notebook contains functions for processing, merging, and saving climate data from the NASA Earth Exchange Global Daily Downscaled Projections (NEX-GDDP-CMIP6) and weather data from from Oikolab, a provider of weather and climate datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e696b292-ae6f-4190-9418-79878b5fcc48",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "085a2a1e-c232-40eb-855e-474aa8faf7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from pathlib import Path\n",
    "from scipy.constants import convert_temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7891e8b0-e901-49e4-9e2f-b266e09e0f5a",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bfb968",
   "metadata": {},
   "source": [
    "These functions map the spatial resolution of the weather dataset onto the climate dataset and save the results to an interim subdirectory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2821e09f-595b-4e33-b6b8-bfaf0b73dd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_resolution(ds_climate, ds_weather):\n",
    "    \"\"\"\n",
    "    Maps the resolution of two datasets: a climate dataset and a weather dataset.\n",
    "    It removes duplicates in both datasets and then interpolates the climate dataset\n",
    "    to match the latitude and longitude resolutions of the weather dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - ds_climate: Dataset representing climate data.\n",
    "    - ds_weather: Dataset representing weather data.\n",
    "\n",
    "    Returns:\n",
    "    - Interpolated climate dataset with resolution mapped to the weather dataset's resolution.\n",
    "    \"\"\"\n",
    "    # Remove duplicates from both datasets\n",
    "    ds_climate_cleaned = ds_climate.drop_duplicates(...)\n",
    "    ds_weather_cleaned = ds_weather.drop_duplicates(...)\n",
    "    \n",
    "    # Interpolate the cleaned climate dataset to match the weather dataset's resolution\n",
    "    ds_climate_interpolated = ds_climate_cleaned.interp(\n",
    "        lat=ds_weather_cleaned.latitude, \n",
    "        lon=ds_weather_cleaned.longitude\n",
    "    )\n",
    "    \n",
    "    return ds_climate_interpolated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6eb1c6ad-be7d-4830-bbb5-fb97fd46abd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataset(dataset, folderpath, filename):\n",
    "    \"\"\"\n",
    "    Save the dataset to a netCDF file. \n",
    "    The netCDF file is saved in an interim subdirectory within the specified folder path.\n",
    "    \n",
    "    Parameters:\n",
    "    - dataset: The xarray.Dataset to be saved.\n",
    "    - folderpath: A string specifying the directory path where the netCDF file will be saved.\n",
    "    - filename: The name of the netCDF file to save without an extension.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Create a Path object for folderpath to ensure correct path manipulation\n",
    "    folder = Path(folderpath)\n",
    "    \n",
    "    # Construct the file path for the processed version of the file\n",
    "    filepath = folder / 'interim' / (filename + '.nc')\n",
    "    \n",
    "    dataset.to_netcdf(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14da20a5",
   "metadata": {},
   "source": [
    "These functions convert the climate and weather Xarray datasets into pandas DataFrames. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fb30966-ee4c-49f5-b7d1-d924dbd67993",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_climate_data(dataset):\n",
    "    \"\"\"\n",
    "    Processes climate data by converting an Xarray Dataset to a pandas DataFrame, \n",
    "    creating a combined 'model_scenario' column, converting temperatures from Kelvin \n",
    "    to Fahrenheit, and pivoting the DataFrame for analysis.\n",
    "\n",
    "    Parameters:\n",
    "    - dataset (xarray.Dataset): The input dataset containing climate data. Expected\n",
    "      to have 'model', 'scenario', 'tasmin', 'lat', 'lon', and 'time' variables.\n",
    "\n",
    "    Returns:\n",
    "    - pandas.DataFrame: A pivoted DataFrame with minimum daily Fahrenheit \n",
    "      temperatures for each latitude, longitude, and date combination.\n",
    "    \"\"\"\n",
    "    # Convert the Xarray Dataset into a pandas DataFrame\n",
    "    df = dataset.to_dataframe().dropna().reset_index()\n",
    "    \n",
    "    # Create a new column concatenating the model and scenario columns\n",
    "    df['model_scenario'] = df['model'] + '-' + df['scenario']\n",
    "    \n",
    "    # Convert the time column to datetime format\n",
    "    df['time'] = pd.to_datetime(df['time']).dt.date\n",
    "    \n",
    "    # Convert temperature from Kelvin to Fahrenheit\n",
    "    df['fahrenheit'] = convert_temperature(df['tasmin'], 'kelvin', 'fahrenheit')\n",
    "    \n",
    "    # Pivot the DataFrame\n",
    "    pivot = df.pivot_table(\n",
    "        index=['lat', 'lon', 'time'], \n",
    "        columns='model_scenario', \n",
    "        values='fahrenheit', \n",
    "        aggfunc='min',\n",
    "    ).reset_index()\n",
    "\n",
    "    return pivot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "225990dd-a492-440d-85f7-eec387505d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_weather_data(dataset):\n",
    "    \"\"\"\n",
    "    Processes weather data by converting an Xarray Dataset to a pandas DataFrame, \n",
    "    creating a combined 'model_scenario' column and converting temperatures from \n",
    "    Celsius to Fahrenheit.\n",
    "\n",
    "    Parameters:\n",
    "    - dataset (xarray.Dataset): The input dataset containing climate data. Expected\n",
    "      to have 'time', 'latitude', 'longitude', and 'temperature' variables.\n",
    "\n",
    "    Returns:\n",
    "    - pandas.DataFrame: A pivoted DataFrame with minimum daily Fahrenheit \n",
    "      temperatures for each latitude, longitude, and date combination.\n",
    "    \"\"\"\n",
    "    # Convert the Xarray Dataset into a pandas DataFrame\n",
    "    df = dataset.to_dataframe().dropna().reset_index()\n",
    "    \n",
    "    # Convert the time column to datetime format\n",
    "    df['time'] = pd.to_datetime(df['time']).dt.date\n",
    "    \n",
    "    # Convert temperature from Celsius to Fahrenheit\n",
    "    df['fahrenheit'] = convert_temperature(df['temperature'], 'celsius', 'fahrenheit')\n",
    "\n",
    "    df = df[['latitude', 'longitude', 'time', 'fahrenheit']]\n",
    "    df.columns = ['lat', 'lon', 'time', 'fahrenheit']\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca040d24-0e15-48dc-9dfd-1c5d0059db54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dataframes(df_climate, df_weather):\n",
    "    \"\"\"\n",
    "    Merge preprocessed climate and weather data DataFrames.\n",
    "    \n",
    "    Parameters:\n",
    "    - df_climate: Preprocessed climate data.\n",
    "    - df_weather: Preprocessed weather data.\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame resulting from the merge of climate and weather data.\n",
    "    \"\"\"\n",
    "    # Merge climate and weather data\n",
    "    df = pd.merge(df_climate, df_weather, how='left', on=['lat', 'lon', 'time'])\n",
    "    \n",
    "    # Drop rows with any missing values resulting from the merge\n",
    "    return df.dropna()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d57eea87-b400-4621-b74e-5ed587de24cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataframe(folderpath, filename, dataframe):\n",
    "    \"\"\"\n",
    "    Saves a given dataframe to a Parquet file with GZIP compression in a specified\n",
    "    directory and subdirectory ('processed').\n",
    "\n",
    "    Parameters:\n",
    "    - folderpath: str, the path to the main folder where the file will be saved.\n",
    "    - filename: str, the name of the file to be saved.\n",
    "    - dataframe: DataFrame, the pandas DataFrame to save.\n",
    "    \"\"\"    \n",
    "    # Create a Path object for folder_path to ensure correct path manipulation\n",
    "    folder = Path(folderpath)\n",
    "\n",
    "    # Combine the folder path and file name to create the full path to the file\n",
    "    filepath = folder / 'processed' / (filename + '.parquet.gzip')\n",
    "    \n",
    "    dataframe.to_parquet(filepath, compression='gzip')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e1caa2-e24a-4305-9bf3-0a1e73b9eb3f",
   "metadata": {},
   "source": [
    "## Execute Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "585a0285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw datasets\n",
    "ds_climate_train_raw = xr.open_dataset('../data/raw/CMIP6_train_easternmountain.nc')\n",
    "ds_climate_validate_raw = xr.open_dataset('../data/raw/CMIP6_validate_easternmountain.nc')\n",
    "ds_climate_test_raw = xr.open_dataset('../data/raw/CMIP6_test_easternmountain.nc')\n",
    "ds_climate_project_raw = xr.open_dataset('../data/raw/CMIP6_project_easternmountain.nc')\n",
    "ds_weather = xr.open_dataset('../data/raw/oiko_easternmountain.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ec7285a-db30-4298-93f4-c875bcc60ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map spatial resolution from weather to climate datasets\n",
    "ds_climate_train = map_resolution(ds_climate_train_raw, ds_weather)\n",
    "ds_climate_validate = map_resolution(ds_climate_validate_raw, ds_weather)\n",
    "ds_climate_test = map_resolution(ds_climate_test_raw, ds_weather)\n",
    "ds_climate_project = map_resolution(ds_climate_project_raw, ds_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15e7ae7e-6199-47e2-964b-2081d31d21d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_dataset(ds_climate_train, '../data', 'CMIP6_train_easternmountain_interpolated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23e7f39e-b818-4579-bf25-82a05c5a3b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_dataset(ds_climate_validate, '../data', 'CMIP6_validate_easternmountain_interpolated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b647406b-3fcf-48ca-9689-d43da5a7167d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_dataset(ds_climate_test, '../data', 'CMIP6_test_easternmountain_interpolated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4347b404-17d8-47fb-b58b-6a844e076f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_dataset(ds_climate_project, '../data', 'CMIP6_project_easternmountain_interpolated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab369440-ba9c-4f00-bfbd-e46561029a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert datasets to dataframes\n",
    "df_climate_train = process_climate_data(ds_climate_train)\n",
    "df_climate_validate = process_climate_data(ds_climate_validate)\n",
    "df_climate_test = process_climate_data(ds_climate_test)\n",
    "df_climate_project = process_climate_data(ds_climate_project)\n",
    "df_weather = process_weather_data(ds_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3a716ed-bbd4-44de-811a-6251418a1ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge dataframes\n",
    "df_train = merge_dataframes(df_climate_train, df_weather)\n",
    "df_validate = merge_dataframes(df_climate_validate, df_weather)\n",
    "df_test = merge_dataframes(df_climate_test, df_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6bd35a97-9d01-49a0-b9a1-dee0645e0e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_dataframe('../data', 'df_easternmountain_train', df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5c6ad7a-e7a3-4474-9a13-91714bf499b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_dataframe('../data', 'df_easternmountain_validate', df_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50cc8f9c-e809-481f-9e5d-5967c9b78aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_dataframe('../data', 'df_easternmountain_test', df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74a92200-dd49-4bbd-b386-e571325b8c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_dataframe('../data', 'df_easternmountain_project', df_climate_project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa5f9fa4-bf6a-44c7-9436-ab6d05474063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_dataframe('../data', 'df_easternmountain_weather', df_weather)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
